{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/graphml/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataloader import EmbeddingsDataloader\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import one_hot\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, learning_rate, batch_size, frames_per_datapoint,\\\n",
    "                 train_data_overlap, epochs):\n",
    "    \n",
    "    model = model(frames_per_datapoint).to(device)\n",
    "    # print(model)\n",
    "    best_model = copy.deepcopy(model)\n",
    "    train_dataset = EmbeddingsDataloader(width=frames_per_datapoint)\n",
    "    test_dataset = EmbeddingsDataloader(width=frames_per_datapoint, mode='test', overlap=True)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=512)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    def test():\n",
    "        with torch.no_grad():\n",
    "            total_attempts = 0\n",
    "            correct = 0\n",
    "            for x, y in test_dataloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                res = model(x)\n",
    "                # label = one_hot(y[:,-1].type(torch.int64), num_classes=9).float()\n",
    "                total_attempts += x.shape[0]\n",
    "                correct += float((y[:,-1] == torch.argmax(res, dim=-1)).sum())\n",
    "            return round(correct / total_attempts, 3)\n",
    "\n",
    "\n",
    "    steps = 0\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    loss_count = 0\n",
    "    for epoch in range(epochs):\n",
    "        total_attempts = 0\n",
    "        correct = 0\n",
    "        index = 0\n",
    "        test_acc_last = 0\n",
    "        best_test_acc = 0\n",
    "        for i, (x, y) in enumerate(train_dataloader):\n",
    "\n",
    "            # get the samples\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # run through the model\n",
    "            optimizer.zero_grad()\n",
    "            res = model(x)\n",
    "\n",
    "            # perform gradient descent\n",
    "            label = one_hot(y[:,-1].type(torch.int64), num_classes=9).float()\n",
    "            # print(res.shape, label.shape)\n",
    "            loss = criterion(res, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # run test\n",
    "\n",
    "            # update metrics\n",
    "            loss_count = loss.item()\n",
    "            steps += 1\n",
    "            losses.append(loss.item())\n",
    "            total_attempts += x.shape[0]\n",
    "            corr = (y[:,-1] == torch.argmax(res, dim=-1)).sum()\n",
    "            correct += corr\n",
    "            if i % (len(train_dataloader) // 20) == 0:\n",
    "                test_acc = test()\n",
    "                test_accs.append(test_acc)\n",
    "                test_acc_last = test_acc\n",
    "                if test_acc > best_test_acc:\n",
    "                    best_test_acc = test_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "            else:\n",
    "                test_accs.append(test_acc_last)\n",
    "            print(f\"epoch {epoch}/{epochs-1}, done fraction: {round(index / len(train_dataloader), 2)}, loss is {round(loss_count, 3)}, accuracy {round((correct / total_attempts).item(), 3)}, test_acc: {test_acc}\", end='\\r')\n",
    "            index += 1\n",
    "            # time.sleep(0.01)\n",
    "    return losses, test_accs, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Run:\n",
    "    def __init__(self, model=SingleLayerPerceptron, learning_rate=0.01, batch_size=16,\\\n",
    "                 frames_per_datapoint=16, train_data_overlap=False, epochs=2):\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.frames_per_datapoint = frames_per_datapoint\n",
    "        self.train_data_overlap = train_data_overlap\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def run_experiment(self):\n",
    "        losses, test_accs, best_model = run_training(self.model, self.learning_rate, self.batch_size,\\\n",
    "                     self.frames_per_datapoint, self.train_data_overlap, self.epochs)\n",
    "        self.losses, self.test_accs, self.best_model = losses, test_accs, best_model\n",
    "        return losses, test_accs, best_model\n",
    "    \n",
    "    def plot_results(self):\n",
    "        nrm_losses = (np.array(self.losses) / max(self.losses)) * max(self.test_accs)\n",
    "        plt.plot(range(len(self.losses)), self.test_accs, label='test accuracies')\n",
    "        plt.plot(range(len(self.losses)), nrm_losses, label='losses')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample run\n",
    "# r = Run()\n",
    "# r.run_experiment()\n",
    "# r.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "combinations progress:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1, done fraction: 1.0, loss is 5.785, accuracy 0.688, test_acc: 0.656663\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "combinations progress:   6%|▋         | 1/16 [00:43<10:53, 43.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1, done fraction: 0.98, loss is 0.791, accuracy 0.75, test_acc: 0.675755\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "combinations progress:  12%|█▎        | 2/16 [01:07<07:28, 32.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1, done fraction: 0.98, loss is 6.018, accuracy 0.726, test_acc: 0.65444\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "combinations progress:  19%|█▉        | 3/16 [01:32<06:15, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/1, done fraction: 0.4, loss is 85.125, accuracy 0.458, test_acc: 0.33118\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "combinations progress:  19%|█▉        | 3/16 [01:49<07:54, 36.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     model, width \u001b[39m=\u001b[39m elems\n\u001b[1;32m     18\u001b[0m     r \u001b[39m=\u001b[39m Run(model\u001b[39m=\u001b[39mmodel, frames_per_datapoint\u001b[39m=\u001b[39mwidth)\n\u001b[0;32m---> 19\u001b[0m     losses, test_accs, best_model \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mrun_experiment()\n\u001b[1;32m     20\u001b[0m     results\u001b[39m.\u001b[39mappend((\u001b[39mmax\u001b[39m(test_accs), losses, test_accs, \u001b[39mstr\u001b[39m((model, width))))\n\u001b[1;32m     21\u001b[0m results\u001b[39m.\u001b[39msort()\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mRun.run_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_experiment\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     losses, test_accs, best_model \u001b[39m=\u001b[39m run_training(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\\\n\u001b[1;32m     13\u001b[0m                  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframes_per_datapoint, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_data_overlap, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepochs)\n\u001b[1;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_accs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_model \u001b[39m=\u001b[39m losses, test_accs, best_model\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m losses, test_accs, best_model\n",
      "Cell \u001b[0;32mIn[2], line 63\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(model, learning_rate, batch_size, frames_per_datapoint, train_data_overlap, epochs)\u001b[0m\n\u001b[1;32m     61\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m corr\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(train_dataloader) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m20\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     test_acc \u001b[39m=\u001b[39m test()\n\u001b[1;32m     64\u001b[0m     test_accs\u001b[39m.\u001b[39mappend(test_acc)\n\u001b[1;32m     65\u001b[0m     test_acc_last \u001b[39m=\u001b[39m test_acc\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mrun_training.<locals>.test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[0;32m---> 19\u001b[0m     x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     res \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     21\u001b[0m     \u001b[39m# label = one_hot(y[:,-1].type(torch.int64), num_classes=9).float()\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# this is a simple experiment to see if there is a link\n",
    "# between model capacity and performance\n",
    "\n",
    "import itertools\n",
    "models = [\n",
    "    SingleLayerPerceptron,\n",
    "    MultiLayerPerceptron2,\n",
    "    MultiLayerPerceptron3,\n",
    "    MultiLayerPerceptron4,\n",
    "]\n",
    "widths = [\n",
    "    1,\n",
    "    4,\n",
    "    16,\n",
    "    64,\n",
    "]\n",
    "combinations = list(itertools.product(models, widths))\n",
    "results = []\n",
    "for i, elems in tqdm(enumerate(combinations), total=len(combinations), desc='combinations progress'):\n",
    "    model, width = elems\n",
    "    r = Run(model=model, frames_per_datapoint=width)\n",
    "    losses, test_accs, best_model = r.run_experiment()\n",
    "    results.append((max(test_accs), losses, test_accs, str((model, width))))\n",
    "results.sort()\n",
    "[print(R) for R in results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
